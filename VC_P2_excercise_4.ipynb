{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practica 2 VISION POR COMPUTADOR TAREA 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.0 (SDL 2.28.4, Python 3.11.9)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import cv2  # pip install opencv-python\n",
    "import numpy as np # pip install numpy\n",
    "import matplotlib.pyplot as plt # pip install matplotlib\n",
    "import random\n",
    "import mediapipe as mp # pip install mediapipe    o en caso de problemas    pip install mediapipe --user\n",
    "import pygame  # pip install pygame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAREA: Tras ver el video de  [Virtual air guitar](https://youtu.be/FIAmyoEpV5c?feature=shared) decidimos proponer un demostrador parecido al de Virtual air guitar pero con un piano, donde el usuario una vez ponga las dos manos en la pantalla podra tocar un piano como si fuese de verdad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero para poder resolver esta tarea es decompnerlo en partes, por lo que lo primero es poder detectar las manos, para ello tomamos un codigo de partida, el cual modificamos ciertas partes para nuestra demostracion [Codigo de partida en Medium](https://lvimuth.medium.com/hand-detection-in-python-using-opencv-and-mediapipe-30c7b54f5ff4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandTrackingDynamic:\n",
    "    def __init__(self, mode=False, maxHands=2, detectionCon=0.5, trackCon=0.5):\n",
    "        self.__mode__ = mode\n",
    "        self.__maxHands__ = maxHands\n",
    "        self.__detectionCon__ = detectionCon\n",
    "        self.__trackCon__ = trackCon\n",
    "        self.handsMp = mp.solutions.hands\n",
    "        self.hands = self.handsMp.Hands(max_num_hands=maxHands)\n",
    "        self.mpDraw = mp.solutions.drawing_utils\n",
    "        self.tipIds = [4, 8, 12, 16, 20]  # IDs de las puntas de los dedos\n",
    "\n",
    "    def findFingers(self, frame):\n",
    "        imgRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        self.results = self.hands.process(imgRGB)\n",
    "        return frame\n",
    "\n",
    "    def findPosition(self, frame):\n",
    "        hands_positions = []\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            for handLms in self.results.multi_hand_landmarks:\n",
    "                lmsList = []\n",
    "                for id, lm in enumerate(handLms.landmark):\n",
    "                    h, w, c = frame.shape\n",
    "                    cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "                    lmsList.append([id, cx, cy])\n",
    "\n",
    "                hands_positions.append(lmsList)\n",
    "\n",
    "                # Dibuja el contorno de la mano como un guante\n",
    "                self.draw_glove(frame, lmsList)\n",
    "\n",
    "        return hands_positions\n",
    "\n",
    "    def draw_glove(self, frame, lmsList):\n",
    "        points = [(lm[1], lm[2]) for lm in lmsList]\n",
    "\n",
    "        # Agregar la muñeca a los puntos, ajustando su posición hacia abajo\n",
    "        wrist_x = lmsList[0][1]\n",
    "        wrist_y = lmsList[0][2] + 50  # Desplazar hacia abajo (ajusta este valor según sea necesario)\n",
    "        points.insert(0, (wrist_x, wrist_y))  # Añadir muñeca al principio\n",
    "\n",
    "        points = np.array(points, dtype=np.int32)\n",
    "\n",
    "        # Dibuja el contorno de la mano como un guante\n",
    "        cv2.fillPoly(frame, [points], (255, 255, 255))  # Color blanco para el guante\n",
    "        cv2.polylines(frame, [points], isClosed=True, color=(255, 255, 255), thickness=10)  # Dibuja el contorno\n",
    "\n",
    "    def findFingerUp(self, lmsList):\n",
    "        fingers = []\n",
    "        if lmsList[self.tipIds[0]][1] > lmsList[self.tipIds[0] - 1][1]:\n",
    "            fingers.append(1)\n",
    "        else:\n",
    "            fingers.append(0)\n",
    "\n",
    "        for id in range(1, 5):\n",
    "            if lmsList[self.tipIds[id]][2] < lmsList[self.tipIds[id] - 2][2]:\n",
    "                fingers.append(1)\n",
    "            else:\n",
    "                fingers.append(0)\n",
    "\n",
    "        return fingers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo siguiente a tener en cuenta es que tenemos que tener los audios de piano para que el usuario pueda tocar el piano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_sound(zone, sustained=False):\n",
    "    volume = random.uniform(0.5, 1.0)  # Volumen aleatorio entre 0.5 y 1.0\n",
    "    sound = None\n",
    "\n",
    "    # Seleccionar sonido dependiendo de si es sostenido\n",
    "    if sustained:\n",
    "        sound_files = [\n",
    "            'air_piano_sounds/do_stretched.wav',\n",
    "            'air_piano_sounds/re_stretched.wav',\n",
    "            'air_piano_sounds/mi_stretched.wav',\n",
    "            'air_piano_sounds/fa_stretched.wav',\n",
    "            'air_piano_sounds/sol_stretched.wav',\n",
    "            'air_piano_sounds/la_stretched.wav',\n",
    "            'air_piano_sounds/si_stretched.wav',\n",
    "            'air_piano_sounds/do_octave_stretched.wav'\n",
    "        ]\n",
    "    else:\n",
    "        sound_files = [\n",
    "            'air_piano_sounds/do.wav',\n",
    "            'air_piano_sounds/re.wav',\n",
    "            'air_piano_sounds/mi.wav',\n",
    "            'air_piano_sounds/fa.wav',\n",
    "            'air_piano_sounds/sol.wav',\n",
    "            'air_piano_sounds/la.wav',\n",
    "            'air_piano_sounds/si.wav',\n",
    "            'air_piano_sounds/do_octave.wav'\n",
    "        ]\n",
    "\n",
    "    if 1 <= zone <= 8:\n",
    "        sound = pygame.mixer.Sound(sound_files[zone - 1])\n",
    "        sound.set_volume(volume)  # Establece el volumen\n",
    "        sound.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos los metodos para que el usuario detecte cuando esta en modo air piano y cuando no dibujando las zonas, indicandoselo con texto y demas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_piano_posture(fingers):\n",
    "    # Definimos la postura de piano como cuando los dedos índice, medio, anular y meñique están levantados\n",
    "    return fingers[1] == 1 and fingers[2] == 1 and fingers[3] == 1 and fingers[4] == 1\n",
    "\n",
    "def draw_centered_text(frame, text, font_scale, color):\n",
    "    # Calcular el tamaño del texto\n",
    "    (text_width, text_height), baseline = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, 2)\n",
    "    \n",
    "    # Calcular las coordenadas para centrar el texto\n",
    "    center_x = (frame.shape[1] - text_width) // 2\n",
    "    center_y = (text_height + 30)  # Colocar el texto en la parte superior\n",
    "\n",
    "    # Dibujar el texto varias veces para simular negrita\n",
    "    for dx in [-1, 0, 1]:  # Desplazamiento para simular negrita\n",
    "        cv2.putText(frame, text, (center_x + dx, center_y), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, 2)\n",
    "\n",
    "def draw_zones(frame, zone_states):\n",
    "    zone_width = frame.shape[1] // 8\n",
    "    for i in range(8):\n",
    "        x_start = i * zone_width\n",
    "        x_end = (i + 1) * zone_width\n",
    "        color = (50, 50, 50)  # Color base de las zonas\n",
    "        if zone_states[i]:\n",
    "            color = (0, 255, 0)  # Color verde para zonas activas\n",
    "        cv2.rectangle(frame, (x_start, 0), (x_end, frame.shape[0]), color, 2)\n",
    "        # Opcional: Añadir etiquetas de nota\n",
    "        notas = ['Do', 'Re', 'Mi', 'Fa', 'Sol', 'La', 'Si', 'Do']\n",
    "        cv2.putText(frame, notas[i], (x_start + 10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez todo listo vamos tomando la camara y cuando las dos manos esten juntas cada movimiento de los dedos del usuario hara sonar el piano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    pygame.mixer.init()  # Inicia pygame mixer para sonidos\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    detector = HandTrackingDynamic()\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)  # Aumentar la resolución para mejor visualización\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open camera\")\n",
    "        exit()\n",
    "\n",
    "    # Variables para controlar sonidos sostenidos\n",
    "    sustained_notes = [False] * 8  # Estado de las notas sostenidas\n",
    "    zone_states = [False] * 8  # Estado visual de las zonas\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Cerrar con la tecla 'Escape'\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == 27:  # Escape\n",
    "            break\n",
    "\n",
    "        frame = detector.findFingers(frame)\n",
    "        hands_positions = detector.findPosition(frame)\n",
    "\n",
    "        # Ponemos todo si tenemos dos manos\n",
    "        if len(hands_positions) == 2:\n",
    "\n",
    "            for handLms in hands_positions:\n",
    "                if len(handLms) != 0:\n",
    "                    # Verificar si la mano tiene la postura de \"piano\"\n",
    "                    fingers = detector.findFingerUp(handLms)\n",
    "                    \n",
    "                    # Revisar si hay dedos en la postura de piano\n",
    "                    if is_piano_posture(fingers):\n",
    "                        # Asegúrate de que fingers tenga al menos 8 elementos\n",
    "                        if len(fingers) >= 8:\n",
    "                            for i in range(1, 9):\n",
    "                                if fingers[i] == 1:\n",
    "                                    if not sustained_notes[i - 1]:\n",
    "                                        play_sound(i, sustained=True)\n",
    "                                        sustained_notes[i - 1] = True  # Marcar nota como sostenida\n",
    "                                        zone_states[i - 1] = True  # Activar estado visual\n",
    "                                else:\n",
    "                                    sustained_notes[i - 1] = False  # Resetear estado al bajar el dedo\n",
    "                                    zone_states[i - 1] = False  # Desactivar estado visual\n",
    "                    else:\n",
    "                        # Obtener coordenadas del dedo índice (ID 8)\n",
    "                        x, y = handLms[8][1], handLms[8][2]\n",
    "\n",
    "                        # Dividir la pantalla en 8 zonas y reproducir sonido basado en la posición\n",
    "                        current_zone = min(max((x // (frame.shape[1] // 8)) + 1, 1), 8)  # Cálculo más conciso de zonas\n",
    "                        play_sound(current_zone)\n",
    "                        zone_states[current_zone - 1] = True  # Activar estado visual\n",
    "\n",
    "            # Añadir un fondo semi-transparente\n",
    "            overlay = frame.copy()\n",
    "            alpha = 0.3  # Transparencia\n",
    "            cv2.rectangle(overlay, (0, 0), (frame.shape[1], 100), (0, 0, 0), -1)  # Fondo negro semi-transparente\n",
    "            cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0, frame)\n",
    "            draw_zones(frame, zone_states)\n",
    "            draw_centered_text(frame, 'Air Piano', 1, (255, 255, 255))  # Dibujar el texto\n",
    "\n",
    "        cv2.imshow('Air Piano use your hands', frame)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 ('FACES')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea3a1ee99ce326e593ddb52cd278556d527fcb6552c40e2a47b1efb9d0183637"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
