<h1 align="center">üåü Pr√°ctica 2 - Visi√≥n por Computador (Curso 2024/2025)</h1>

<img align="left" width="200" height="160" src="img/octo_cat.png"></a>
Se han completado todas las tareas solicitadas de la **Pr√°ctica 2** para la asignatura **Visi√≥n por Computador**. Funciones b√°sicas de OpenCV.

*Trabajo realizado por*:

[![GitHub](https://img.shields.io/badge/GitHub-Heliot%20J.%20Segura%20Gonzalez-green?style=flat-square&logo=github)](https://github.com/kratoscordoba7)

[![GitHub](https://img.shields.io/badge/GitHub-Alejandro%20David%20Arzola%20Saavedra%20-red?style=flat-square&logo=github)](https://github.com/AlejandroDavidArzolaSaavedra)

## üõ†Ô∏è Librer√≠as Utilizadas

[![NumPy](https://img.shields.io/badge/NumPy-%23013243?style=for-the-badge&logo=numpy)](Link_To_Your_NumPy_Page)
[![OpenCV](https://img.shields.io/badge/OpenCV-%23FD8C00?style=for-the-badge&logo=opencv)](Link_To_Your_OpenCV_Page)
[![Matplotlib](https://img.shields.io/badge/Matplotlib-%43FF6400?style=for-the-badge&logo=matplotlib&logoColor=white)](Link_To_Your_Matplotlib_Page)
[![Mediapipe](https://img.shields.io/badge/Mediapipe-%23D9D9D9?style=for-the-badge&logo=mediapipe)](Link_To_Your_Mediapipe_Page)
[![Pygame](https://img.shields.io/badge/Pygame-%23223B57?style=for-the-badge&logo=pygame)](Link_To_Your_Pygame_Page)


---
## üöÄ C√≥mo empezar

Para comenzar con el proyecto, sigue estos pasos:

> [!NOTE]  
> Debes de situarte en un environment configurado como se defini√≥ en el cuaderno de la pr√°ctica de [otsedom](https://github.com/otsedom/otsedom.github.io/blob/main/VC/P1/README.md#111-comandos-basicos-de-anaconda) y adicionalmente instalarte pygame y mediapipe, en el propio cuaderno pone como realizarlo.

### Paso 1: Abrir VSCode y situarse en el directorio:
   
   `C:\Users\TuNombreDeUsuario\anaconda3\envs\VCP2`
   
### Paso 2: Clonar y trabajar en el proyecto localmente (VS Code)
1. **Clona el repositorio**: Ejecuta el siguiente comando en tu terminal para clonar el repositorio:
   ```bash
   git clone https://github.com/kratoscordoba7/VCP2.git
   ```
2. Una vez clonado, todos los archivos han de estar situado en el environment del paso 1

### Paso 3: Abrir Anaconda prompt y activar el envioroment:
   ```bash
   conda activate NombreDeTuEnvironment
   ```
Tras estos pasos deber√≠a poder ejecutar el proyecto localmente

---

<h2 align="center">üìã Tareas</h2>

# Tarea 1 M√°ximo filas y columnas de p√≠xeles blancos 

TAREA: Realizar la cuenta de p√≠xeles blancos por filas (en lugar de por columnas). Determinar el m√°ximo para filas y columnas (uno para cada) y muestra el n√∫mero de filas con un n√∫mero de p√≠xeles blancos mayor o igual que 0.95*m√°ximo.

## Funci√≥n Principal: CannyToRowPlot(canny, text)
```python
def CannyToRowPlot(canny):
    # Cuenta el n√∫mero de p√≠xeles blancos (255) por fila, el 1 indica que es por filas. Primero los computa y despu√©s lo simplifica en un solo entero
    row_counts = cv2.reduce(canny, 1, cv2.REDUCE_SUM, dtype=cv2.CV_32SC1)
    """"
    Notas ==> : implica que toma TODOS los valores (Al fin y al cabo es un array de arrays, toma el primer valor, y √∫nico, de cada array)
                Se obtiene un array de longitud igual al alto, porque se eval√∫a por columnas. 
                Cada valor representa el n√∫mero de p√≠xeles blancos por columnas.
            
    """
    rows = row_counts[:, 0] / (255 * canny.shape[1])

    # Determina el valor m√°ximo de p√≠xeles blancos por fila.
    maxfil = np.max(rows)

    # Encuentra las filas con un n√∫mero de p√≠xeles blancos mayor o igual que 0.95 * maxfil
    threshold = 0.95 * maxfil
    filas_con_maximos = np.where(rows >= threshold)[0] # Se toma el cero porque la funci√≥n np.where() devuelve un objeto array con listas dentro.

    # Muestra el resultado gr√°ficamente
    plt.figure()
    plt.subplot(1, 2, 1)
    plt.axis("off")
    plt.title("Canny")
    plt.imshow(canny, cmap='gray')

    plt.subplot(1, 2, 2)
    plt.title("Respuesta de Canny por filas")
    plt.xlabel("Filas")
    plt.ylabel("% p√≠xeles")
    plt.plot(rows)

    plt.xlim([0, canny.shape[0]])

    # Imprime los resultados
    print(f"Valor m√°ximo de p√≠xeles blancos por fila: {maxfil}")
    print(f"N√∫mero de filas con m√°s del 95% del valor m√°ximo: {len(filas_con_maximos)}")
    print(f"Posiciones de las filas con m√°s del 95% del valor m√°ximo: {filas_con_maximos}")
```

Esta funci√≥n recibe dos par√°metros:

   - canny: Una imagen binaria (generalmente una imagen resultante de la aplicaci√≥n del algoritmo de Canny) que contiene p√≠xeles blancos (255) que representan los bordes detectados.
   - text: Un string que define el t√≠tulo de la imagen y el gr√°fico, permitiendo una descripci√≥n personalizada para cada ejecuci√≥n.

## Reducci√≥n de la imagen a valores por fila:
   - Se calcula la suma de los valores de p√≠xeles por cada fila de la imagen usando la funci√≥n cv2.reduce. El resultado es un vector de valores que representa la cantidad total de p√≠xeles blancos por fila.
     
## Normalizaci√≥n del valor de cada fila:
   - El conteo de p√≠xeles blancos se normaliza dividiendo entre el producto de 255 (valor de p√≠xel blanco) y el n√∫mero de columnas de la imagen, obteniendo as√≠ el porcentaje de p√≠xeles blancos por cada fila de la imagen.
     
## Detecci√≥n de filas con m√°ximo porcentaje de bordes:
   - Se calcula el valor m√°ximo de p√≠xeles blancos en una fila (maxfil) y se establece un umbral del 95% de ese valor m√°ximo.
   - Se identifica las filas que tienen una proporci√≥n de p√≠xeles blancos mayor o igual al 95% del valor m√°ximo.
    
## Visualizaci√≥n:
   - La funci√≥n genera una gr√°fica utilizando matplotlib que muestra:
   - La imagen original procesada por Canny (en una escala de grises).
   - Un gr√°fico que muestra la distribuci√≥n de p√≠xeles blancos por cada fila.

<div align="center">
   <img src="img/canny_por_filas.png" width="580" height="400">
</div>

## Salida:
La funci√≥n imprime en consola los siguientes valores:
   - El valor m√°ximo de p√≠xeles blancos por fila (maxfil).
   - El n√∫mero de filas que contienen al menos el 95% del valor m√°ximo de p√≠xeles blancos.
   - Las posiciones de estas filas en la imagen.

```
Ejemplo salida para la imagen del mandril:
   - Valor m√°ximo de p√≠xeles blancos por fila: 0.4296875
   - N√∫mero de filas con m√°s del 95% del valor m√°ximo: 2
   - Posiciones de las filas con m√°s del 95% del valor m√°ximo: [ 12 100]
```

# Tarea 2 Umbralizado a la imagen de Sobel

**Valor m√°ximo de p√≠xeles blancos por columna:** 0.59765625

**TAREA:** Se aplic√≥ un umbralizado a la imagen resultante del filtro Sobel (convertida a 8 bits) y se realiz√≥ un conteo de p√≠xeles no nulos por filas y columnas, similar al realizado con la salida de Canny. A continuaci√≥n, se calcularon los valores m√°ximos de conteo por filas y columnas, y se determinaron las filas y columnas que superan el 95% del valor m√°ximo. Estas filas y columnas fueron resaltadas en la imagen utilizando primitivas gr√°ficas.

- **Valor del Umbral:** 170
- **N√∫mero de columnas con m√°s del 95% del valor m√°ximo:** 4  
- **Posiciones de las columnas con m√°s del 95% del valor m√°ximo:** [261, 262, 263, 264]

- **Valor m√°ximo de p√≠xeles blancos por fila:** 0.55078125  
- **N√∫mero de filas con m√°s del 95% del valor m√°ximo:** 2  
- **Posiciones de las filas con m√°s del 95% del valor m√°ximo:** [508, 509]
<br>
<br>

<div align="center">
   <img src="img/mono_sobel.png" width="680" height="400">
</div>

<br>
<br>

Al comparar los resultados obtenidos de las im√°genes procesadas por Sobel y Canny, se observa que el m√©todo Canny produce un mayor n√∫mero de filas y columnas con p√≠xeles no nulos en comparaci√≥n con Sobel. Adem√°s, los histogramas de Sobel muestran una distribuci√≥n m√°s homog√©nea en las filas y columnas, mientras que en Canny se evidencia una mayor disparidad en la distribuci√≥n de los valores. Esta diferencia sugiere que Canny es m√°s eficaz para resaltar caracter√≠sticas en la imagen, proporcionando un mayor contraste en la detecci√≥n de bordes en comparaci√≥n con Sobel.

<div align="center">
   <img src="img/grafico_sobel.png" width="620" height="440">
</div>

<br>
<br>

Para el c√≥digo, reutilizamos parte de lo desarrollado en la tarea 2 y modificamos segmentos del c√≥digo proporcionado por el profesor para optimizar su uso mediante funciones. Esto nos permiti√≥ evitar la duplicaci√≥n de c√≥digo, especialmente en la secci√≥n de c√°lculo de columnas. Un fragmento de c√≥digo interesante que muestra c√≥mo umbralizamos la imagen utilizando el filtro Sobel es el siguiente:

```python
# Aplicar un filtro Gaussiano para suavizar la imagen original y eliminar altas frecuencias
ggris = cv2.GaussianBlur(gris, (3, 3), 0)

# Calcular el gradiente en ambas direcciones (horizontal y vertical)
sobelx = cv2.Sobel(ggris, cv2.CV_64F, 1, 0)  # Gradiente en x
sobely = cv2.Sobel(ggris, cv2.CV_64F, 0, 1)  # Gradiente en y

# Combinar ambos resultados
sobel = cv2.add(sobelx, sobely)

# Definir el valor del umbral
valorUmbral = 170

# Convertir la imagen a 8 bits
sobel8 = np.uint8(sobel)

# Obtener la imagen umbralizada seg√∫n el valor definido
res, imagenUmbralizada = cv2.threshold(sobel8, valorUmbral, 255, cv2.THRESH_BINARY)
```

# Tarea 3 Demostrador que captura las im√°genes de la c√°mara

TAREA: Proponer un demostrador que capture las im√°genes de la c√°mara, y les permita exhibir lo aprendido en estas dos pr√°cticas ante quienes no cursen la asignatura :). Es por ello que adem√°s de poder mostrar la imagen original de la webcam, incluya al menos dos usos diferentes de aplicar las funciones de OpenCV trabajadas hasta ahora.

## Funcionalidades
El script ofrece cuatro modos de procesamiento de im√°genes, cada uno activado mediante diferentes teclas del teclado:

   - Modo Original (Tecla '0'): Muestra la imagen de la c√°mara sin modificaciones.
```python
def normal(frame):
    cv2.imshow('Imagen original', frame)
```
   - Modo Canny (Tecla '1'): Aplica el filtro de detecci√≥n de bordes de Canny.
```python
def NormalToCanny(frame):
    canny = cv2.Canny(frame, 100, 400)
    cv2.imshow('Imagen Canny', canny)
```
<div align="center">
   <img src="img/Canny.png" width="680" height="400">
</div>
   - Modo de Segmentaci√≥n de Color Azul (Tecla '2'): Detecta y mantiene el color azul en la imagen, mientras el resto se muestra en escala de grises.
<div align="center">
   <img src="img/BotellaSegmentacion.png" width="680" height="400">
   <img src="img/EstucheSegmentacion.png" width="680" height="400">
</div>

```python
def segmentacion_color_azul(frame):
    # Convertir la imagen de BGR a HSV
    hsv, lower_blue, upper_blue = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV), np.array([100, 150, 50]), np.array([140, 255, 255])
    
    # Crear una m√°scara que detecte los p√≠xeles dentro del rango del color azul,  
    # es un array donde los valores que no se encuentren en el intervalo valen cero
    mask = cv2.inRange(hsv, lower_blue, upper_blue)
    
    # Crear la imagen en escala de grises, podr√≠a tener color pero al haberla convertido primero a escala de grises se ver√≠a en blanco y negro
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    gray_colored = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)
    
    # Combinar la imagen en color con la imagen en escala de grises usando la m√°scara
    resultado = np.where(mask[:, :, np.newaxis] != 0, frame, gray_colored)
    
    cv2.imshow('Segmentacion de color (Azul)', resultado)
```
   - Modo Filtro Sepia (Tecla '3'): Aplica un filtro sepia, dando a la imagen un tono c√°lido estilo vintage.
<div align="center">
   <img src="img/SepiaSegmentacion.png" width="680" height="400">
</div>

```python
def filtro_sepia(frame):
    sepia_filter = np.array([[0.272, 0.534, 0.131], [0.349, 0.686, 0.168], [0.393, 0.769, 0.189]])
    sepia = cv2.transform(frame, sepia_filter)
    cv2.imshow('Filtro Sepia', sepia)
```

Aqui se muestran m√°s imagenes que demuestran el funcionamiento del codigo:
<div align="center">
   <table>
   <td width="50%">
      <div align="center">
         <img src="img/color.png"  width="400" alt="Imagen Color">
      </div>                                                 
   </td>
   <td width="50%">
      <div align="center">                                       
         <img src="img/sepia.png" width="400" alt="Imagen Sepia">
      </div>
   </td>
   </table>
   <table>
   <td width="50%">
      <div align="center">
         <img src="img/canny.png"  width="400" alt="Imagen Filtro Canny">
      </div>                                                 
   </td>
   <td width="50%">
      <div align="center">                                       
         <img src="img/segmentacion_azul.png" width="400" alt="Imagen Segmentacion azul">
      </div>
   </td>
   </table>
</div>



# Tarea 4 Reinterpretaci√≥n de la parte de procesamiento de la imagen

Despu√©s de ver el video de **Virtual Air Guitar**, decidimos reinterpretar la parte del procesamiento de im√°genes creando un piano virtual en el aire. En este sistema, el usuario puede tocar el piano utilizando el movimiento de sus dedos. Para ello, comenzamos con un c√≥digo base para la detecci√≥n de manos [Medium MediaPipe](https://lvimuth.medium.com/hand-detection-in-python-using-opencv-and-mediapipe-30c7b54f5ff4) y, a partir de este punto, desarrollamos el resto de la funcionalidad necesaria para llevar a cabo la tarea.

<div align="center">
   <img src="img/air_piano.png" width="420" height="240">
</div>

A continuaci√≥n, presentamos un peque√±o fragmento del c√≥digo responsable del control de las manos para hacer sonar el piano:

```python
if is_piano_posture(fingers):
   if len(fingers) >= 8:
      for i in range(1, 9):
         if fingers[i] == 1:
            if not sustained_notes[i - 1]:
               play_sound(i, sustained=True)
               sustained_notes[i - 1] = True  # Marcar nota como sostenida
               zone_states[i - 1] = True  # Activar estado visual
            else:
               sustained_notes[i - 1] = False  # Resetear estado al bajar el dedo
               zone_states[i - 1] = False  # Desactivar estado visual
         else:
            x, y = handLms[8][1], handLms[8][2]
            current_zone = min(max((x // (frame.shape[1] // 8)) + 1, 1), 8)
            play_sound(current_zone)
            zone_states[current_zone - 1] = True  
```


---

> [!IMPORTANT]  
> Los archivos presentados aqu√≠ son una modificaci√≥n de los archivos originales de [otsedom](https://github.com/otsedom/otsedom.github.io/tree/main/VC).

> [!WARNING]  
> Este codigo puede usarse sin problemas tampoco hay que preocuparse por el copyright de los sonidos del piano puesto que forman parte de [Freesound](https://freesound.org/) y la licencia
> que tienen es de libre uso 'Creative Commons 0'


---

## üìö Bibliograf√≠a

1. [Opencv](https://docs.opencv.org/4.x/dc/da5/tutorial_py_drawing_functions.html)
2. [Medium MediaPipe](https://lvimuth.medium.com/hand-detection-in-python-using-opencv-and-mediapipe-30c7b54f5ff4)
3. [Sonidos de Piano Freesound](https://freesound.org/people/Jaz_the_MAN_2/packs/17749/)

---

**Universidad de Las Palmas de Gran Canaria**  
EII - Grado de Ingenier√≠a Inform√°tica  
Obra bajo licencia de Creative Commons Reconocimiento - No Comercial 4.0 Internacional

---
